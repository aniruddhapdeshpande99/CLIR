{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Reading the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Data/Articles/English/\"\n",
    "dataset = {}\n",
    "doc_index = 0\n",
    "file_names = [x[2] for x in os.walk(str(data_folder))]\n",
    "file_names = file_names[0] #Above value is a 2D array\n",
    "for i in file_names:\n",
    "    with open(data_folder+i) as json_file:\n",
    "        article = json.load(json_file)\n",
    "        curr_article = {}\n",
    "        curr_article['title'] = article['title'].strip() #Using strip to remove leading and trailing spaces\n",
    "        curr_article['text'] = article['text'].strip() \n",
    "        curr_article['index'] = doc_index\n",
    "        #i[:-5] so as to remove .json from the key of the dictionary\n",
    "        dataset[i[:-5]] = curr_article\n",
    "        doc_index = doc_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Converts upper case letters to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3.2 Removes stop words like and, are, is, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in words:\n",
    "        if w not in stop_words and len(w) > 1:\n",
    "            new_text = new_text + \" \" + w\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Removes punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Removes apostrophe punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Stemmer for English that removes inflections like tried => try + ed (ed is removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    stemmer= PorterStemmer()\n",
    "    \n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        new_text = new_text + \" \" + stemmer.stem(w)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6 Converts numerals to words like 19 => nineteen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.7 Calls all of the above functions to preprocess the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_apostrophe(data)\n",
    "    data = remove_stop_words(data)\n",
    "    data = convert_numbers(data)\n",
    "#     data = stemming(data)\n",
    "    data = remove_punctuation(data)\n",
    "    data = convert_numbers(data)\n",
    "#     data = stemming(data) #needed again as we need to stem the words\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Preprocessing the extracted data (title and text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset.keys():\n",
    "    dataset[i]['processed_text'] = word_tokenize(str(preprocess(dataset[i]['text'])))\n",
    "    dataset[i]['processed_title'] = word_tokenize(str(preprocess(dataset[i]['title'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Calculating DF for all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = {}\n",
    "\n",
    "for i in dataset.keys():\n",
    "    tokens = dataset[i]['processed_text']\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "\n",
    "    tokens = dataset[i]['processed_title']\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab_size = len(DF)\n",
    "total_vocab = [x for x in DF]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Returns the frequency of the input word throughout the entire set of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Calculating TF-IDF for the Text of the Article. \n",
    "#### Here normal TF-IDF is used as Title (of the Article) weight would be added to this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = {}\n",
    "\n",
    "for i in dataset.keys():\n",
    "    \n",
    "    tokens = dataset[i]['processed_text']\n",
    "    \n",
    "    counter = Counter(tokens + dataset[i]['processed_title'])\n",
    "    words_count = len(tokens + dataset[i]['processed_title'])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        tf_idf[dataset[i]['index'], token] = tf*idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Calculating TF-IDF for the Title of the Article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_title = {}\n",
    "\n",
    "for i in dataset.keys():\n",
    "    \n",
    "    tokens = dataset[i]['processed_title']\n",
    "    counter = Counter(tokens + dataset[i]['processed_text'])\n",
    "    words_count = len(tokens + dataset[i]['processed_text'])\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N+1)/(df+1)) #numerator is added 1 to avoid negative values\n",
    "        \n",
    "        tf_idf_title[dataset[i]['index'], token] = tf*idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Merging TF-IDF of Text and Title of the Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tf_idf:\n",
    "    tf_idf[i] *= alpha\n",
    "    \n",
    "for i in tf_idf_title:\n",
    "    tf_idf[i] = tf_idf_title[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. TF-IDF Cosine Similarity Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1 Vectorising TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.zeros((N, total_vocab_size))\n",
    "for i in tf_idf:\n",
    "    try:\n",
    "        ind = total_vocab.index(i[1])\n",
    "        D[i[0]][ind] = tf_idf[i]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vector(tokens):\n",
    "\n",
    "    Q = np.zeros((len(total_vocab)))\n",
    "    \n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "\n",
    "    query_weights = {}\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        \n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = math.log((N+1)/(df+1))\n",
    "\n",
    "        try:\n",
    "            ind = total_vocab.index(token)\n",
    "            Q[ind] = tf*idf\n",
    "        except:\n",
    "            pass\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2 Search and Retrieve using Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(k, query):\n",
    "    print(\"Cosine Similarity\")\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "    \n",
    "    print(\"\\nQuery:\", query)\n",
    "    print(\"\")\n",
    "    print(tokens)\n",
    "    \n",
    "    d_cosines = []\n",
    "    \n",
    "    query_vector = gen_vector(tokens)\n",
    "    \n",
    "    for d in D:\n",
    "        d_cosines.append(cosine_sim(query_vector, d))\n",
    "        \n",
    "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    print(out)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity\n",
      "\n",
      "Query: Salman Khan\n",
      "\n",
      "['salman', 'khan']\n",
      "\n",
      "[129 145  35 120   8 114 171  17  75 105]\n"
     ]
    }
   ],
   "source": [
    "Q = cosine_similarity(10, \"Salman Khan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Ranked Article is as follows:\n",
      "\n",
      "Title : Amitabh Bachchan:Did You Know Amitabh Bachchan Was Once Mistaken For Salman Khan? His Response Was Epic!\n",
      "\n",
      "Did You Know Amitabh Bachchan Was Once Mistaken For Salman Khan? His Response To It Was Quite Cool!\n",
      "Did You Know Amitabh Bachchan Was Once Mistaken For Salman Khan? His Response To It Was Quite Cool!\n",
      "Have you ever been mistaken for somebody else? For us, it might be a usual thing. But can you imagine celebrities being in a situation where they are confused for other stars?\n",
      "In the west, it has happened quite a lot of times. For instance, once a fan asked This Is Us star Justin Hartley about his wife Blake. If you didn’t get the drift, he was mistaken for Ryan Reynolds. Can you imagine?\n",
      "Recently, Amitabh Bachchan also revealed about one such incident that happened with him. Big B was once confused as Salman Khan. I know, even I want to know who that person was?\n",
      "“We were shooting on the streets in Glasgow and then I had to walk on the footpath. As I was walking, a car went by and our desi bhai was sitting in the car, who waved and said: 'Hey, Salman Khan, how you doing?' So, I waved back at him and walked on. What to do,\" the Badla actor told Shah Rukh Khan,” Amitabh Bachchan recently revealed once again at the promotions of Badla.\n",
      "Don't Miss 529 SHARES 8.9 K SHARES 3.1 K SHARES 248 SHARES 20.7 K SHARES\n",
      "T 2850 - I walk the street of Glasgow by myself .. until a car drives by and occupant yells out .. \" hey Salman Khan how you doin' .. \" pic.twitter.com/RJ5neJXBaj — Amitabh Bachchan (@SrBachchan) June 27, 2018\n",
      "If you remember, he had also tweeted about it last year writing, “I walk the street of Glasgow by myself .. until a car drives by and occupant yells out .. \" hey Salman Khan how you doin' ..”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10th ranked Article is as follows:\n",
      "\n",
      "Title : Kareena Kapoor Has A Dating Advice For Sara Ali Khan And It Holds True For All The Newcomers\n",
      "\n",
      "Kareena Kapoor Has A Dating Advice For Sara Ali Khan And It Holds True For All The Newcomers\n",
      "Kareena Kapoor Has A Dating Advice For Sara Ali Khan And It Holds True For All The Newcomers\n",
      "Bollywood actress Kareena Kapoor is known to be the most fearless stars we have in the industry. Whether it's openly talking about her Whatsapp group with her girls which gives her all the gossip or admitting that she's a fashionista even in her gym clothes, Bebo is unapologetic about her views.\n",
      "Twitter\n",
      "She has completed 19 years in Bollywood and done over 50 films. Married to the Prince of Pataudi, Saif Ali Khan and the mother of Taimur, everyone wants a sneak peek of Kareena and her daily routine.\n",
      "Right from her gym, to her make up, airport spotting, attending birthday parties, Kareena is one of the most searched celebrities on Instagram. And now her step-daughter Sara Ali Khan has also made her debut in Bollywood.\n",
      "Twitter\n",
      "Don't Miss 554 SHARES 3.7 K SHARES 8.9 K SHARES 1.6 K SHARES\n",
      "And unlike a typical scenario of a stepmom household, Sara and Kareena are extremely fond of each other. Infact, in an episode of Koffee With Karan, Sara admitted she's extremely happy that her father Saif Ali Khan got married to Kareena Kapoor as she was too happy to have Pooh in the house.\n",
      "Sara's friends feel she must have conspired this marriage as she is a big fan of the actress. Well, feelings are mutual as Kareena also absolutely loved Sara's performance in Kedarnath and Simmba.\n",
      "Instagram\n",
      "In one of the celebrity chat shows, Kareena was asked what is that one dating advice she's d like to give Sara. And like always, the stylish mom and celebrity had an on fleek answer. She advised Sara not to date her first hero.\n",
      "Well, quite an apt one considering most of the newcomers end up dating their first co-stars. This advice is not only good for Sara but for all the upcoming actors too. What do you think?\n",
      "Kareena Kapoor will next be seen opposite Akshay Kumar in Good News.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.keys():\n",
    "    if dataset[i]['index'] == Q[0]:\n",
    "        print('Top Ranked Article is as follows:\\n')\n",
    "        print('Title : %s'%dataset[i]['title'])\n",
    "        print(\"\")\n",
    "        print(dataset[i]['text'])\n",
    "        print(\"\\n\\n\\n\")\n",
    "\n",
    "for i in dataset.keys():\n",
    "    if dataset[i]['index'] == Q[-1]:\n",
    "        print(\"%sth ranked Article is as follows:\\n\"%len(Q))\n",
    "        print('Title : %s'%dataset[i]['title'])\n",
    "        print(\"\")\n",
    "        print(dataset[i]['text'])\n",
    "        print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
